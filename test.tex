%to make: latexmk -pdf -pvc --shell-escape
\documentclass[sigconf, anonymous=false]{acmart}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{subcaption}
\usepackage{lipsum}
\usepackage{layouts}
\usepackage{mathtools}
\setcounter{secnumdepth}{3}
\setcounter{tocdepth}{3}

\newcommand{\seconds}[1]{\mbox{#1\,\textrm{s}}}
\newcommand{\vx}{\mathbf{x}}
\newcommand{\paren}[1]{\left(#1\right)}
\newcommand{\floor}[1]{{\lfloor #1 \rfloor}}
\newcommand{\ceil}[1]{{\lceil #1 \rceil}}
\newcommand{\op}[1]{\operatorname{#1}}
\newcommand{\opp}[2]{\operatorname{#1}\paren{#2}}

\usetikzlibrary{external}
\tikzexternalize

\begin{document}

\acmConference[GECCO '18]{the Genetic and Evolutionary Computation Conference 2018}{July 15--19, 2018}{Kyoto, Japan}{}
\acmYear{2018}
\copyrightyear{2018}

%\title{Multi-objective Analysis of MAP-Elites Mutation Operators}
%\title{Multi-objective Analysis Applied to Mutations in MAP-Elites}
\title{Multi-objective Analysis of MAP-Elites Performance}
\author{Eivind Samuelsen}
\affiliation{%
	\institution{University of Oslo}
	\department{Department of Informatics}
	\streetaddress{Postboks 1080, Blindern}
	\postcode{0316}
	\city{Oslo}
	\country{Norway}}
\email{eivinsam@ifi.uio.no}
\author{Kyrre Glette}
\affiliation{%
	\institution{University of Oslo}
	\department{Department of Informatics}
	\streetaddress{Postboks 1080, Blindern}
	\postcode{0316}
	\city{Oslo}
	\country{Norway}}
\email{kyrrehg@ifi.uio.no}

\begin{abstract}
In certain complex optimization tasks, it becomes necessary to use multiple measures to characterize the performance of different algorithms. 
% The MO method
This paper presents a method that combines ordinal effect sizes with Pareto dominance to analyze such cases.  Since the method is ordinal, it can also generalize across different optimization tasks even when the performance measurements are differently scaled.  Through a case study, we show that this method can discover and quantify relations that would be difficult to deduce using a conventional measure-by-measure analysis. 
% The MAP-Elites case
This case study applies the method to the evolution of robot controller repertoires using the MAP-Elites algorithm.
Here, we analyze the search performance across a large set of parametrizations; varying mutation size and operator type, as well as map resolution, across four different robot morphologies. 
We show that the average magnitude of mutations has a bigger effect on outcomes than their precise distributions.
\end{abstract}

\maketitle


\section{Introduction}


\subsection{General intro}
\begin{itemize}
\item map-elites / quality diversity methods popular for exploring something and generating repertoires \cite{Duarte2017}
\begin{itemize}
\item e.g. exploring possible outcomes in morphology, niches in art
\item e.g. generating a repertoire of behaviors for controlling a robot
\end{itemize}
\item ...
\end{itemize}


\subsection{Previous / related work}
\begin{itemize}
\item quality diversity / illumination \cite{Lehman2011, Mouret2015}
\item map-elites \cite{Mouret2015}
\item attempts of frameworks / comparisons of different qd approaches \cite{Pugh2016, Cully2017}
\item cliffs delta studies?
\item mutation operators variants?
\end{itemize}


\subsection{Positioning}
\begin{itemize}
\item Even if map-elites normally finds solutions given enough time(?), it would still be necessary to tune the parameters, e.g. mutation rate, to achieve desired results
\begin{itemize}
\item for performance - e.g. could be relevant if a repertoire should be built for several morphologies (happens to be our case), or find another example
\item for other tuning purposes, just to make things work

\end{itemize}

\item map-elites has multiple (dual) performance "dimensions": coverage, precision, ..., and thus calls for pareto-based analysis method
\begin{itemize}
\item This is relevant e.g. in the case of generating a repertoire of behaviors, wanting to explore well as well as having good solutions for each bin
\item Previous approaches did not consider this
\item ...
\end{itemize}

\item also justify the mutation operators study?
\begin{itemize}
\item there are some common mutation operators in ER, such as "some hard" or "all hard" (need to explain), give examples
\item while seeming intuitive, gives different behavior for different number of dimensions?
\item while (maybe?) some studies in other fields (how to find out)?
\item it should be studied also within the context of ER (why? - do we have a special case?)
\end{itemize}

\item we need to locate possible similar studies from ancient EC lore

\end{itemize}

\subsection{Previous work and motivation}
\begin{itemize}
\item We evolved some morphologies earlier
\item we want them to move around - mapelitess
\end{itemize}

\subsection{Contributions}
\begin{itemize}
\item Mutation operator variants
\begin{itemize}
\item All vs some
\item Hard vs soft
\item Magnitude distribution plot?
\end{itemize}
\item Pareto-based analysis method
\begin{itemize}
\item Pareto comparison $\rightarrow$ Cliff's delta
\item Bagplot w/trace
\item Effect size tables
\end{itemize}
\end{itemize}

\newpage
\subsection{Outline}
\subsubsection*{Methods \& Experiment}

\begin{itemize}
\item Pareto analysis (\autoref{method:effect-size}, \autoref{method:pareto})
\item Performance measures (\autoref{method:meas})
\item Mutation (\autoref{method:mutate})
\item Optimization task (\autoref{method:task})
\item Control system (\autoref{method:control})
\item Robots and simulator (\autoref{method:robots})
\end{itemize}

\subsubsection*{Results}
\subsubsection*{Discussion}
\subsubsection*{Conclusion}



\section{Methods}

\subsection{Simulated Robots}\label{method:robots}

\begin{itemize}
\item Say something about PhysX
\end{itemize}

The algorithm was run on four of the five robot morphologies from \cite{Samuelsen2015}, retaining their original numbering. The fifth morphology, robot 1, provoked simulator instabilities that we were currently unable to rectify. 


\subsection{Control System}\label{method:control}
Each joint is controlled by a open-loop controller with four parameters: phase offset $\phi$, duty cycle $D$, and two amplitudes $a_0$ and $a_1$, as shown in Figure \ref{fig:control}. The duty cycle is encoded as a continuous parameter $d$ such that 
\[ 
 D = 
 \begin{cases} 
 d-\floor{d} & \floor{d}\text{ is even} \\
 \ceil{d}-d  & \text{otherwise} \\
 \end{cases}
\]
as illustrated in Figure \ref{fig:dwrap}. This lets $d$ be mutated freely as a continuous variable while mapping it to the correct range without discontinuities and without getting stuck at the extreme values. The parameters are encoded symmetrically, so that each joint on the left side of the body share duty cycle and amplitude parameters with the corresponding joint on the right side. The phase offset is also coded differentially, i.e. it is $\phi$ on the left side and $\phi + \Delta\phi$ on the right.

\begin{figure}
\begin{subfigure}[t]{\columnwidth}
\input{R/ctrl-plot.tex}
\vspace{-18pt}
\caption{Joint set point as a function of $t$}
\label{fig:control}
\end{subfigure}
\begin{subfigure}[t]{\columnwidth}
\input{R/d-plot.tex}
\vspace{-18pt}
\caption{Wrapping $d$ onto $\left[0, 1\right]$}
\label{fig:dwrap}
\end{subfigure}
\caption{Control system parametrization}
\end{figure}


\subsection{Optimization Task}\label{method:task}

\begin{itemize}
\item MAP-elites details (behavior dimensions, ...)
\item Physics simulation 
\item controller
\item ...?
\end{itemize}

\begin{figure}
\input{R/fwd-plot.tex}
\vspace{-18pt}
\caption{Forward movement estimation}
\end{figure}


\subsection{Mutation}\label{method:mutate}
\begin{figure}
\input{R/mutation-density.tex}
\vspace{-12pt}
\caption{Simulated distribution density of the magnitude of the four tested mutation operators}
\end{figure}
\begin{itemize}
\item $k$-D normal distribution produces a narrow range of magnitudes, does this affect optimization performance?
\item Testing five $sigma$ values: 0.05, 0.1, 0.2, 0.4 and 0.8
\item Tested candidates:
\begin{itemize}
\item All hard: normal distribution applied to all parameters, constant $\sigma/\sqrt{k-1}$
\item All soft: normal distribution applied to all parameters, but with the standard deviation $\sigma/\sqrt{k-1}$ multiplied by a variable from a uniform distribution
\item Some hard: normal distribution with standard deviation $\sigma$ applied to each parameter with a probability $1/k$
\item Some soft: normal distribution with standard deviation $\sigma$ applied to one randomly picked parameter and then to each remaining parameter with a probability $1/(k-1)$
\end{itemize}
\end{itemize}


\subsection{Controlled parameters}
\begin{itemize}
\item Sigma
\item Map size
\item Mutation type
\item Robot morphology
\end{itemize}

\begin{table}
\caption{Experiment setup}
\begin{tabular}{p{1.5in}p{1.3in}}
\hline
Parameter & Value \\
\hline
PhysX version & 3.4 \\
Ground-robot friction & 0.3 / 0.3 \\
Timestep & \seconds{$128^{-1}$} \\
\hline
Control system period & \seconds{1} \\
Pre-evaluation periods & 1 \\
Evaluation periods & 4 \\
Samples per period & 4 \\
Total evaluations per run & 20000 \\
\hline
Initial population & 100 \\
Initial mutation & all-hard \\
Initial $\sigma$ & 0.5 \\
\hline
\begin{tabular}{@{}p{0.9in}r@{}}
Robots & robot2 \\
       & robot3 \\
       & robot4 \\
       & robot5 \\
\end{tabular} & 
\begin{tabular}{@{}l@{}}
4 legs, 6 joints \\
4 legs, 9 joints \\
4 legs, 10 joints \\
6 legs, 14 joints \\
\end{tabular} \\
Map sizes & $5\times5$, $7\times7$, $9\times9$ \\
$\sigma$ values & 0.01, 0.1, 0.2, 0.4, 0.8 \\
Mutation types & all-hard, some-hard, \\
               & all-soft, some-soft \\
Total combinations & 240 \\
Runs per combination & 12 \\
\hline
\end{tabular}
\end{table}


\subsection{Performance Measures}\label{method:meas}
\label{sec:perfmeas}

Performance measures simular to those in \cite{Mouret2015} and \cite{Pugh2016} are used;
presicion is defined as the average score of filled cells: 
\[ \opp{P}{m} = \frac{\opp{QD-score}{m}}{\opp{n}{m}} = \frac{1}{\opp{n}{m}}\sum_{\vx \in G}m\paren{\vx} \]
where $m\paren{x}$ is the score in cell $x$ of map $m$ or zero if empty, and $\opp{n}{m}$ is the number of filled cells in $m$.
Coverage is defined as the fraction of cells filled:
\[ \opp{C}{m} = \frac{\opp{n}{m}}{N} \]
where $N$ is the total number of cells in the map. 
Finally, global precision is defined as the average score across all cells, which can be expressed as
\[ \opp{G}{m} = \frac{\opp{QD-score}{m}}{N} = \opp{P}{m}\opp{C}{m} \]
These definitions differs from those in \cite{Mouret2015} in that they don't scale the cell scores against the best observed score for each cell.

\subsection{Cliff's Delta}\label{method:effect-size}
\begin{itemize}
\item Problems with by-value comparisons: Trouble visualizing and reporting variance, must compare for one morphology/case at a time
\end{itemize}
Cliff's delta, or the d statistic \cite{Cliff1993}, an ordinal estimate of how separated two distributions are, and can be expressed as 
\begin{equation} \label{eq:d}
d = \opp{p}{a > b} - \opp{p}{a < b}
\end{equation}
It can either be calculated exactly by comparing all possible pairs of observations from the samples, approximated by comparing a number of random pairs, or through is relation 
\[ d_{ab} = \frac{2U}{mn} - 1 \]
to the Wilcoxon-Mann-Whitney (WMW) U statistic. Because of this linear relation, testing whether $d$ is likely to be zero corresponds to doing a WMW U test. The d statistic is also related to Vargha and Delaney's effect size $\hat{A}$ \cite{Vargha2000} by
\[ d_{ab} = 2\hat{A}_{ab} - 1\]
Since it is ordinal, we can use it to measure differences across incomparable groups, for example compare the performance of two algorithms across different benchmarks, or in this case, different parametrizations of an algorithm across different robot morphologies. Assuming equal weight to the different groups, this can be done by ensuring that comparisons are always done between observations in the same group, and weighting the groups equally. This can be calculated as
\[ d_{ab} = \frac{1}{|G|}\sum_{g\in G} d\paren{a\,|\,g,\ b\,|\,g} \]

\subsection{Pareto Domination}\label{method:pareto}
\begin{itemize}
\item Problem with one-measure-at-a-time comparisons: May miss Pareto-optimal outcomes
\item Cannot use scalar sorting to compute efficiently, but can be approximated by sampling a random pairing for large $m$ and $n$, and bootstrapped to generate confidence intervals, and thus hypothesis tests
\end{itemize}
Considering the performance measures defined in Subsection \ref{sec:perfmeas} from the perspective of multi-objective optimization, we can see that we have three objectives we want to optimize, and so, rather than analyzing which algorithms perform well with regards to the objectives individually, we should be interested in to what degree the different algorithms produce superior results with regards to Pareto domination.

As suggested in \cite{Neumann2015}, we can it can replace the comparison operators in (\ref{eq:d}) with Pareto domination, resulting in a measure of what degree one sample dominates the other:
\[ d_{ab} = \opp{p}{a \succ b} - \opp{p}{a \prec b} \]
Like the scalar d statistic, this can be used to compare distribution to decide which is better. Note, however, that the WMW U statistic and test cannot be generalized in the same manner, since Pareto dominance is not able to produce a simple ranking of a sample. 

Being a simple product of the other two objectives, global precision becomes redundant in a Pareto-domination-based analysis, reducing the number of objectives to two. This 


\section{Results}

% \printinunitsof{in}
% Text width is \prntlen{\textwidth}, text height is \prntlen{\textheight}, and column width is \prntlen{\columnwidth}.

\begin{figure*}
\begin{subfigure}[t]{0.33\textwidth}
\input{R/box-coverage-3.tex}
\vspace{-18pt}
\caption{Coverage}
\end{subfigure}
\begin{subfigure}[t]{0.33\textwidth}
\input{R/box-reliability-3.tex}
\vspace{-18pt}
\caption{Reliability}
\end{subfigure}
\begin{subfigure}[t]{0.33\textwidth}
\input{R/box-precision-3.tex}
\vspace{-18pt}
\caption{Precision}
\end{subfigure}
\caption{Boxplots of the three objectives, across robots and parameters. For each of the parameters the data has been adjusted to remove variation from the other two parameters, which is why some of the box whiskers extend below zero}
\end{figure*}

\begin{figure*}
\begin{subfigure}[t]{0.33\textwidth}
\input{R/bags-mapsize.tex}
\vspace{-12pt}
\caption{Map size}
\end{subfigure}
\begin{subfigure}[t]{0.33\textwidth}
\input{R/bags-sigma.tex}
\vspace{-12pt}
\caption{Mutation size}
\end{subfigure}
\begin{subfigure}[t]{0.33\textwidth}
\input{R/bags-mutation.tex}
\vspace{-12pt}
\caption{Mutation type}
\end{subfigure}
\caption{Precision and coverage grouped by the different variables}
\end{figure*}



\begin{table}
\caption{Effect sizes between map sizes when grouped by mutation size, implying $5 \succ 7 \succ 9$}
\input{R/table-mapsize-sigma.tex}
\end{table}

\begin{table}
\caption{Effect sizes between mutation sizes when grouped by map size, implying $0.4 \succ \left\lbrace 0.8, 0.2 \right\rbrace \succ 0.1 \succ 0.05$}
\input{R/table-sigma-mapsize.tex}
\end{table}

\begin{table}
\caption{Effect sizes between mutation types}
\input{R/table-mutation.tex}
\end{table}

\begin{table}
\caption{Effect sizes between mutation types when grouped by mutation size and and map size}
\input{R/table-mutation-sigma-mapsize.tex}
\end{table}

%\lipsum[6-7]
\begin{itemize}
\item In addition to current plots, also show traditional plots, or at least explain how many plots would be needed (or give an example of one case)
\item ...
\item ...
\end{itemize}


\section{Discussion}
%\lipsum[8-9]
\begin{itemize}
\item Discuss advantage of new plots / method compared to old analysis
\item With reliability you can only have one best combination, viewing it in a pareto fashion exposes a multitude of equally good approaches
\item Comparing the same number of variations using traditional method results in a lot of numbers/figures (see example for one robot)
\item We explored a set of mutation operators and sizes. It seems like the mutation size is much more important than the selection of operator type (from the ones we considered).
\item ...
\end{itemize}


\section{Conclusion}
%\lipsum[10]
\begin{itemize}
\item ...
\item ...
\item ...
\end{itemize}

\bibliographystyle{ACM-Reference-Format}
\bibliography{../bibtex/kyrrehg}


\end{document}
